How To install Swip ?
 --> Install Jdk (1.7.x version)
 --> Install Fuseki (fuseki 1 because use of the larq properties)
 --> Install Tomcat
 
 You will need the following projects to deploy Swip : 
  -NlToPivotGazeetter
  -NlToPivotParser
  -NlToPivotRules
  -Patterns
  -PivotToMappingsSparql
  -SwipWebClient
  -SwipWorkflow 
To deploy these projects, you can generate the .war files (open them with an ide and do a clean-build 
it works for the ones with java source code : all of them expect SwipWebClient). Put the .war files in the 
apache-tomcat-x.y.z/webapps folder + the SwipWebClient folder
You can also deploy these web projects with an ide (netbeans, eclipse,etc.)
 
To set up the fuseki server with your queries and patterns ontologies, you need :
 - to edit your own patterns for your ontology in text format like in Patterns/resources/patterns-musicbrainz.txt~
 - translate your text patterns into rdf by going on the Patterns web page deployed on your tomcat 
	(localhost:80/Patterns/patternsTextToRdf.html) or directly on the swip server : 
	http://swip.univ-tlse2.fr/Patterns/patternsTextToRdf.html 
	//make sure that the SwipPatterns.owl ontology is the right file in Patterns/resources
	save the RDF result in your data folder (data/[dataset]/rdfdata-patterns/) and create the matching
	tdbdata-patterns folder (as described in howToInstallFuseki.txt (with tdbloader)
 - personalize the fuseki config.ttl file by changing your graphs' names and the tdbdata folders' location
 - as in config-musicbrainz.ttl, you might want your fuseki dataset to be separated into 3 named graphs .
	(one for the knowledge base, one for the queries and one for the patterns.)
	You can also add the patterns_copy graph used for the display of patterns in SwipWebClient 
	The names you have chosen for your graphs are to be specified in the configuration section of SwipWebClient

 
To deploy NlToPivotGazetteer, follow howToDeployNlToPivotGazetteer.txt : 
 - copy the gate folder 
 - create the dictionaries folders you need : a folder containing 
	- a config.ttl file in which you specify the path to your rdf files (the ones you want to build the dictionary
	from)	beware : you need to specify a defaultNS by import.
	- a query.txt file : a sparql query to get the index of your dictionary (all the string names for example)
	- possibly a ignoreList.txt
	- the kim.trusted.entities.cache et le snapshot.properties are automatically generated files
 - in the .gapp file, specify the path of your dictionary(ies) folder(s) in the dictionaryPath field like this :  
		<string>dictionaryPath</string>
		<gate.util.persistence.PersistenceManager-URLHolder>
		  <urlString>path_of_your_dicitonary_folder</urlString>
		</gate.util.persistence.PersistenceManager-URLHolder>
 - in NlToPivotGazetteerWS.java, change the path to the gapp file
 WARNING : the gate version on the repository is not compatible with Java8. 
 if a ClassFormatNotCompatible exception occurs,try changing your jre/jdk version to 1.7.x in the tomcat setenv file.
 WARNING : to modify the .gapp file, open it with the GATE gui and change what you need (add or delete lkb gazetteer 
 for example).
 You also need to run GATE with A 1.6 or 1.7 java version. Check the first message displayed when you start Gate,
 if the java version is below 1.8, you can go on File>Restore Application From File and load a .gapp.
 if you have a wrong version of java, open a cmd window, set the JAVA_HOME var to a jdk file 1.7 or 1.6 and run 
 the ant file with the "run" option
		-windows : " cd Path/to/Gate6.1
					set JAVA_HOME=%ProgramFiles%\Java\jdk1.7.x_yz
					bin\ant.bat run"
		-linux: "cd Path/to/Gate6.1
				export JAVA_HOME=...
				./bin/ant run"
 
 To deploy NlToPivotParser, specify the treeTagger directory in TreeTagger.java 
	specify the NlToPivotParser_absolute_path/build/web/WEB-INF/classes/ folder path in MaltParser.java
	!! if you are using Windows, put \\ instead of / as a directory separator in the path

In the config side window, the Larq Param (8.0 as default) is the Larq score minimum for an entity to be taken in account
	if you have no results, you may consider lowering it.
	
	
	
	
	
	
	
	
	
	